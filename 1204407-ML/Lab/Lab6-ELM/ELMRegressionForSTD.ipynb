{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "SB7SjfRxxYkH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "JFRgpCp3xhWm"
      },
      "outputs": [],
      "source": [
        "class ELMRegressor():\n",
        "    def __init__(self, n_hidden_units):\n",
        "        self.n_hidden_units = n_hidden_units\n",
        "\n",
        "    def fit(self, X, labels):\n",
        "        X = np.column_stack([X, np.ones([X.shape[0], 1])])\n",
        "        self.random_weights = np.random.randn(X.shape[1], self.n_hidden_units)\n",
        "        G = np.tanh(X.dot(self.random_weights))\n",
        "        self.w_elm = np.linalg.pinv(G).dot(labels)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.column_stack([X, np.ones([X.shape[0], 1])])\n",
        "        G = np.tanh(X.dot(self.random_weights))\n",
        "        return G.dot(self.w_elm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "4vGD09WUxkC5"
      },
      "outputs": [],
      "source": [
        "diabetes = load_diabetes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtCBEv9Rxm27",
        "outputId": "23052022-b09b-4f91-9309-723729341d06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990749, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06833155, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286131, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04688253,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452873, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00422151,  0.00306441]], shape=(442, 10)),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "vvZjDHhExpuC"
      },
      "outputs": [],
      "source": [
        "x,y = diabetes['data'],diabetes['target']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "azYjimZ6xufT"
      },
      "outputs": [],
      "source": [
        "# train 80% , test 20%\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "BxG6_E9_xyBk"
      },
      "outputs": [],
      "source": [
        "elm = ELMRegressor(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "7EwR7Q_Zx0lF"
      },
      "outputs": [],
      "source": [
        "elm.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.82483033 -0.26609636  1.70855481 ...  0.53830208  2.00923427\n",
            "  -0.53893919]\n",
            " [-1.18705968 -0.31584066  0.2564418  ...  1.51262069  0.07991519\n",
            "  -0.77512242]\n",
            " [-0.65769941  0.42470868  0.201327   ... -0.4227244  -0.86106501\n",
            "   0.21940137]\n",
            " ...\n",
            " [ 0.24955926  1.5649138   1.2688578  ...  1.24776933 -0.28094716\n",
            "   1.33837964]\n",
            " [-0.39655056  0.27463895 -1.03825845 ...  0.77063532  1.32209663\n",
            "   1.28974733]\n",
            " [-0.29028749 -0.77430207  1.42128303 ... -0.19997033  1.29737826\n",
            "   0.56871656]]\n"
          ]
        }
      ],
      "source": [
        "# Random Weight\n",
        "print(elm.random_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2.99520337e+04  1.83478854e+04 -6.92829862e+04 -9.74384004e+03\n",
            "  7.17932164e+03 -8.87893881e+03 -1.64779399e+03 -7.18198837e+03\n",
            " -5.11394764e+03 -6.58176633e+03  1.98632621e+04 -3.27525357e+02\n",
            "  1.19121787e+03 -3.73902044e+03 -1.80829603e+04 -6.00285498e+03\n",
            "  5.59726337e+02  3.21686436e+05 -1.31632101e+04 -8.03918688e+04\n",
            "  9.00554225e+04 -5.45824896e+04  2.77939439e+04 -3.49781427e+04\n",
            " -2.66893286e+03  2.62531412e+04 -7.48304474e+03 -5.84000815e+04\n",
            "  2.42899254e+04  9.75102080e+04  2.37240894e+04 -1.24366600e+03\n",
            "  7.42002782e+03 -2.12063698e+04  3.95456842e+04  7.62215013e+03\n",
            "  1.43976680e+04 -6.67412807e+03  5.47635533e+04  7.44496472e+04\n",
            " -5.57373107e+04 -8.62696060e+03 -3.87442169e+04 -2.25127609e+03\n",
            "  1.48748077e+04  1.19581370e+04 -1.49968564e+04  1.95907721e+04\n",
            " -5.53243180e+04  4.22001609e+03  1.92850663e+04  3.18374521e+04\n",
            " -1.96670427e+04 -1.69596412e+04  6.12997096e+04 -1.03362345e+04\n",
            "  1.41793647e+03 -4.56015658e+03 -4.66850466e+04  2.00514626e+04\n",
            "  2.08858972e+05 -3.31481436e+03 -5.24344431e+03 -1.41149753e+04\n",
            " -2.07603776e+03  2.84849060e+03  1.11604703e+04  8.45333983e+04\n",
            " -4.34068314e+04 -2.44325728e+04 -4.78210707e+03 -3.17444659e+03\n",
            " -1.58391561e+05 -4.34599986e+03  2.49581611e+04  2.06782426e+04\n",
            " -1.01740839e+04  1.35432126e+04  1.74281456e+03  3.71867705e+04\n",
            "  8.50606864e+04  6.28076511e+04 -2.26861097e+02 -1.07354935e+04\n",
            "  1.09864610e+05 -5.36015251e+03 -1.45963885e+05  1.17043585e+03\n",
            "  8.56914723e+03 -7.22689792e+04 -8.26479927e+04 -2.12719012e+04\n",
            "  2.91189140e+04 -2.86735284e+04  3.58101970e+05 -9.62179900e+04\n",
            " -2.52230995e+04  1.21466521e+02  1.67191701e+04 -4.81303373e+03\n",
            " -1.15789315e+03 -3.60755348e+01 -1.02523872e+04 -9.80737894e+03\n",
            "  6.19681641e+04 -2.07487489e+04  3.31357987e+04 -2.82337290e+03\n",
            "  3.08521416e+04  5.31622500e+04 -9.63192808e+02 -2.21545538e+04\n",
            "  1.51028302e+02  7.18810397e+05  2.24054635e+03 -7.17281508e+03\n",
            " -8.83193526e+03  2.31353263e+04 -8.82595848e+04  1.53905596e+04\n",
            "  3.05176943e+03  2.38490444e+04  4.47272215e+04 -9.21266580e+04\n",
            " -1.64171004e+05  2.45569206e+04  4.16873283e+03  5.78110720e+04\n",
            "  8.03744445e+03  2.92172867e+04  4.97778671e+04  4.04417235e+04\n",
            "  4.10509301e+04  1.95093466e+04 -1.21260363e+05 -2.87771896e+04\n",
            "  2.27283816e+04  2.92187051e+05 -8.58436374e+04 -2.84822380e+04\n",
            "  1.15072802e+05 -2.09405407e+04 -2.19398276e+02 -1.63476352e+03\n",
            " -1.11089668e+03 -3.54302141e+04 -1.69939775e+02  4.72632727e+04\n",
            " -1.44917051e+04  3.19396167e+05  1.74856890e+04  2.09675139e+04\n",
            " -4.28741114e+03 -1.01449295e+04 -9.74170117e+03  1.00481739e+04\n",
            " -4.21629041e+05 -1.63818243e+04  4.89918140e+05 -8.20757585e+04\n",
            " -1.37347085e+04  4.45669059e+04  8.78074761e+04  9.67885234e+04\n",
            " -3.34801337e+04  1.47909226e+05  5.09429509e+04  9.24325340e+03\n",
            "  3.27124540e+03 -6.67563825e+03  9.01078761e+04  1.82058899e+04\n",
            "  3.48259501e+04 -4.30528228e+04  2.85110437e+03  3.24750450e+03\n",
            " -1.14351223e+05  2.57046012e+04 -8.14794517e+03  1.06070181e+04\n",
            " -1.07572985e+04  4.74848188e+03  8.22933748e+04 -8.18979586e+04\n",
            "  4.53753060e+04  6.18936597e+02  9.30610856e+03 -1.31190568e+03\n",
            "  2.45628591e+04 -7.03039337e+03  1.11814381e+05 -1.50300635e+04\n",
            " -1.19887538e+05 -1.94463326e+03  1.59886431e+04 -2.12139456e+04\n",
            "  1.83326269e+03 -8.34353756e+02  2.30186491e+04 -2.66460563e+04]\n"
          ]
        }
      ],
      "source": [
        "# Weight Hidden Layer Calculated\n",
        "print(elm.w_elm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQaIbIhix3tV",
        "outputId": "91f33177-8987-4db7-8316-3dd2e92c2d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.09256398 -0.04464164  0.03690653  0.02187239 -0.02496016 -0.01665815\n",
            "  0.00077881 -0.03949338 -0.02251653 -0.02178823]\n",
            "70.0\n",
            "[[ 0.09256398 -0.04464164  0.03690653  0.02187239 -0.02496016 -0.01665815\n",
            "   0.00077881 -0.03949338 -0.02251653 -0.02178823]]\n",
            "[89.86652317]\n"
          ]
        }
      ],
      "source": [
        "print(x_test[1,:])\n",
        "print(y_test[1])\n",
        "x=x_test[1,:].reshape(1,-1)\n",
        "print(x)\n",
        "y_pred = elm.predict(x)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YjFSyp2yY0A",
        "outputId": "1755e5d8-bf23-4994-f1f9-832aa35384f2"
      },
      "outputs": [],
      "source": [
        "#Evaluation\n",
        "std_data = StandardScaler()\n",
        "x_train = std_data.fit_transform(x_train)\n",
        "x_test = std_data.transform(x_test)\n",
        "max_y_train = max(abs(y_train))\n",
        "y_train = y_train / max_y_train\n",
        "y_test = y_test / max_y_train\n",
        "elm = ELMRegressor(100)\n",
        "elm.fit(x_train,y_train)\n",
        "y_pred = elm.predict(x_test)\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "print('MAE',mean_absolute_error(y_test,y_pred))\n",
        "print(\"MSE\",mean_squared_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ClassWork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. ELM1\n",
        "- InClass Test 5 data\n",
        "- hidden units = 100, 200, 250\n",
        "- columns = \"People\", \"Y\", \"100units\", \"200units\", \"250units\"\n",
        "                            , data, error, data, error, data, error\n",
        "- mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No Norm\n",
            "Shound be used 250 units with MAD 27.725784895339892\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y</th>\n",
              "      <th>100units_pred</th>\n",
              "      <th>100units_error</th>\n",
              "      <th>200units_pred</th>\n",
              "      <th>200units_error</th>\n",
              "      <th>250units_pred</th>\n",
              "      <th>250units_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>219.0</td>\n",
              "      <td>128.876592</td>\n",
              "      <td>90.123408</td>\n",
              "      <td>124.529053</td>\n",
              "      <td>94.470947</td>\n",
              "      <td>266.012738</td>\n",
              "      <td>47.012738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70.0</td>\n",
              "      <td>148.499966</td>\n",
              "      <td>78.499966</td>\n",
              "      <td>111.73304</td>\n",
              "      <td>41.733040</td>\n",
              "      <td>40.806294</td>\n",
              "      <td>29.193706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>202.0</td>\n",
              "      <td>155.155965</td>\n",
              "      <td>46.844035</td>\n",
              "      <td>99.678053</td>\n",
              "      <td>102.321947</td>\n",
              "      <td>207.427584</td>\n",
              "      <td>5.427584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230.0</td>\n",
              "      <td>237.590495</td>\n",
              "      <td>7.590495</td>\n",
              "      <td>-10.810924</td>\n",
              "      <td>240.810924</td>\n",
              "      <td>269.958889</td>\n",
              "      <td>39.958889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111.0</td>\n",
              "      <td>127.151438</td>\n",
              "      <td>16.151438</td>\n",
              "      <td>115.760828</td>\n",
              "      <td>4.760828</td>\n",
              "      <td>128.036008</td>\n",
              "      <td>17.036008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total ERROR</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>239.209342</td>\n",
              "      <td></td>\n",
              "      <td>484.097686</td>\n",
              "      <td></td>\n",
              "      <td>138.628924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAD</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>47.841868</td>\n",
              "      <td></td>\n",
              "      <td>96.819537</td>\n",
              "      <td></td>\n",
              "      <td>27.725785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Y 100units_pred  100units_error 200units_pred  \\\n",
              "0            219.0    128.876592       90.123408    124.529053   \n",
              "1             70.0    148.499966       78.499966     111.73304   \n",
              "2            202.0    155.155965       46.844035     99.678053   \n",
              "3            230.0    237.590495        7.590495    -10.810924   \n",
              "4            111.0    127.151438       16.151438    115.760828   \n",
              "Total ERROR                           239.209342                 \n",
              "MAD                                    47.841868                 \n",
              "\n",
              "             200units_error 250units_pred  250units_error  \n",
              "0                 94.470947    266.012738       47.012738  \n",
              "1                 41.733040     40.806294       29.193706  \n",
              "2                102.321947    207.427584        5.427584  \n",
              "3                240.810924    269.958889       39.958889  \n",
              "4                  4.760828    128.036008       17.036008  \n",
              "Total ERROR      484.097686                    138.628924  \n",
              "MAD               96.819537                     27.725785  "
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.DataFrame(columns=[\"Y\", \"100units_pred\", \"100units_error\", \"200units_pred\", \"200units_error\", \"250units_pred\", \"250units_error\"])\n",
        "units = [100, 200, 250]\n",
        "diabetes = load_diabetes()\n",
        "x,y = diabetes['data'],diabetes['target']\n",
        "# train 80% , test 20%\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "work_x_test = x_test[:5]\n",
        "work_y_test = y_test[:5]\n",
        "for unit in units:\n",
        "  elm = ELMRegressor(unit)\n",
        "  elm.fit(x_train, y_train)\n",
        "  y_pred = elm.predict(work_x_test)\n",
        "  data['Y'] = work_y_test\n",
        "  data[f'{unit}units_pred'] = y_pred\n",
        "  data[f'{unit}units_error'] = abs(data['Y']-data[f'{unit}units_pred']) # Absolute deviation\n",
        "\n",
        "# Row Total MAD ERROR\n",
        "# Append \"Y\" last row for \"Total ERROR\" text\n",
        "data.loc['Total ERROR'] = data[[\"100units_error\", \"200units_error\", \"250units_error\"]].sum()\n",
        "# MAD\n",
        "data.loc['MAD', '100units_error'] = data.loc['Total ERROR', '100units_error'] / len(work_y_test) # Mean Absolute deviation\n",
        "data.loc['MAD', '200units_error'] = data.loc['Total ERROR', '200units_error'] / len(work_y_test) # Mean Absolute deviation\n",
        "data.loc['MAD', '250units_error'] = data.loc['Total ERROR', '250units_error'] / len(work_y_test) # Mean Absolute deviation\n",
        "\n",
        "# Convert all columns to numeric\n",
        "data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# find min mad and print amount units should be used\n",
        "min_mad = data.loc['MAD'].min()\n",
        "min_mad_unit = data.loc['MAD'].idxmin()\n",
        "print(\"No Norm\")\n",
        "print(\"Shound be used\", min_mad_unit.replace('units_error', ''), \"units with MAD\", min_mad)\n",
        "\n",
        "# Set NaN values to empty string\n",
        "data = data.fillna('')\n",
        "\n",
        "data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
